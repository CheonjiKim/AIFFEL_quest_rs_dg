{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c1e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51bec1",
   "metadata": {},
   "source": [
    "### 1. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4072262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기\n",
    "chatbot_file_path = \"ChatbotData.csv\"\n",
    "\n",
    "data = pd.read_csv(chatbot_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84df5336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505f3f4",
   "metadata": {},
   "source": [
    "### 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff1d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 단위 텍스트 전처리\n",
    "def preprocess_sentence(sentence):\n",
    "    # 소문자 변환\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # 알파벳, 한글, 숫자, 문장부호를 제외한 모든 문자를 삭제\n",
    "    sentence = re.sub(\"[^a-zA-Z0-9가-힣.?!,]\", \"\", sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a2ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 단위 전처리\n",
    "def preprocess_data(data):\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for q, a in zip(data['Q'], data['A']):\n",
    "        questions.append(preprocess_sentence(q))\n",
    "        answers.append(preprocess_sentence(a))\n",
    "\n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2baa9e5",
   "metadata": {},
   "source": [
    "### 3. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f0de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기로 Mecab 이용\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94aaad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 말뭉치 생성 함수\n",
    "def build_corpus(df, tokenizer, max_token_length=50):\n",
    "    # 중복 제거\n",
    "    tmp = df.copy()\n",
    "    print(f'데이터 크기 (원본): {len(tmp)}')\n",
    "    tmp.drop_duplicates(subset=['Q'], inplace=True)\n",
    "    print(f'데이터 크기 (Q 중복 제거 후): {len(tmp)}')\n",
    "    #tmp.drop_duplicates(subset=['A'], inplace=True)\n",
    "    #print(f'데이터 크기 (A 중복 제거 후): {len(tmp)}')\n",
    "\n",
    "    # 전처리\n",
    "    questions, answers = preprocess_data(tmp)\n",
    "\n",
    "    # 토큰화, 필터링\n",
    "    que_corpus = []\n",
    "    ans_corpus = []\n",
    "    for q, a in zip(questions, answers):\n",
    "        q_tokens = tokenizer.morphs(q)\n",
    "        a_tokens = tokenizer.morphs(a)\n",
    "        if len(q_tokens) < max_token_length and len(a_tokens) < max_token_length:\n",
    "            que_corpus.append(q_tokens)\n",
    "            ans_corpus.append(a_tokens)\n",
    "        else:\n",
    "            print(f'토큰 길이 초과 문장: {q}, {a}')\n",
    "\n",
    "    print(f'질문 말뭉치 크기: {len(que_corpus)}, 대답 말뭉치 크기: {len(ans_corpus)} ')\n",
    "    return que_corpus, ans_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9b59b",
   "metadata": {},
   "source": [
    "#### 디버깅\n",
    "- build_corpus 구현이 노드에서 정의한 사양과 다름\n",
    "- 노드: 전처리 -> 토큰화 -> 필터링 -> 중복제거 순서로 처리, 소스 문장 데이터, 타겟 문장 데이터, 토크나이저를 입력으로 받음\n",
    "- 구현: 중복제거 -> 전처리 -> 토큰화 -> 필터링 순서로 처리 (중복제거를 제일 먼저 함), 소스 문장, 타겟 문장이 하나로 묶인 DataFrame을 입력으로 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01af9bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기 (원본): 11823\n",
      "데이터 크기 (Q 중복 제거 후): 11662\n",
      "질문 말뭉치 크기: 11662, 대답 말뭉치 크기: 11662 \n"
     ]
    }
   ],
   "source": [
    "# 말뭉치 생성\n",
    "que_corpus, ans_corpus = build_corpus(data, mecab, 50)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3c200aab",
   "metadata": {},
   "source": [
    "#### 디버깅\n",
    "- 대답에 대해서도 중복 제거를 하면 데이터 크기가 크게 줄어듬 ==> **대답에 대해서는 중복 제거를 하지 않음**\n",
    "![image.png](attachment:image.png)\n",
    "- 토큰 길이를 50으로 제한했으나, 50을 초과하는 문장은 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc074b0",
   "metadata": {},
   "source": [
    "### 4. Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aa5b416",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'Vocab' on <module 'gensim.models.word2vec' from '/opt/conda/lib/python3.9/site-packages/gensim/models/word2vec.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33/3471039413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpretrained_word2vec_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ko.bin\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mword2vec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_word2vec_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0;34m\"Try loading older model using gensim-3.8.3, then re-saving, to restore \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                 \"compatibility with current code.\")\n\u001b[0;32m-> 1942\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1928\u001b[0m         \"\"\"\n\u001b[1;32m   1929\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1930\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1931\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \"\"\"\n\u001b[1;32m   1459\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'Vocab' on <module 'gensim.models.word2vec' from '/opt/conda/lib/python3.9/site-packages/gensim/models/word2vec.py'>"
     ]
    }
   ],
   "source": [
    "# 미리 학습된 Word2Vec 모델을 불러옴\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "pretrained_word2vec_file_path = \"ko.bin\"\n",
    "\n",
    "word2vec_model = Word2Vec.load(pretrained_word2vec_file_path)"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "4e39c56c",
   "metadata": {},
   "source": [
    "#### 디버깅\n",
    "- 미리 학습된 word2vec 모델을 로드할 때, 아래와 같은 에러가 발생함\n",
    "![image-2.png](attachment:image-2.png)\n",
    "- 인터넷 검색을 통해 gensim의 버전 문제임을 확인\n",
    "- 버전을 3.8.3, 3.8.1 로 다운그레이드 했으나, 여전히 문제가 발생함\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "- **오픈소스 생태계가 성공하지 못하는 이유 중에 하나가 라이브러리 하위 호환성 유지 문제라고 생각함**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1be911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim                        4.1.2\r\n"
     ]
    }
   ],
   "source": [
    "# 설치된 gensim 버전 확인\n",
    "!pip list | grep gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83df9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim 다운그레이드\n",
    "#!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a018b56",
   "metadata": {},
   "source": [
    "- **미리 학습된 Word2Vec 모델을 불러오지 못하는 이슈를 해결하지 못해서, augmentation 과정 생략**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c8077",
   "metadata": {},
   "source": [
    "### 5. 데이터 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "879742db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미리 정의된 word index\n",
    "PAD_INDEX = 0\n",
    "START_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNKNOWN_INDEX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea18762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 함수 - 패딩도 추가됨\n",
    "def vectorize(question_corpus, answer_corpus):\n",
    "    # 시작/종료 토큰 추가\n",
    "    print(f'질문: {len(question_corpus)}, 대답: {len(answer_corpus)}')\n",
    "    answer_corpus = [[\"<start>\"] + answer + [\"<end>\"] for answer in answer_corpus]\n",
    "\n",
    "    # 결합\n",
    "    corpus =  question_corpus + answer_corpus\n",
    "    print(f'전체: {len(corpus)}')\n",
    "\n",
    "    # 사전 생성\n",
    "    word_to_index = {}\n",
    "    word_to_index[\"<pad>\"] = PAD_INDEX\n",
    "    word_to_index[\"<start>\"] = START_INDEX\n",
    "    word_to_index[\"<end>\"] = END_INDEX\n",
    "    word_to_index[\"<unknown>\"] = UNKNOWN_INDEX\n",
    "\n",
    "    word_index = 4\n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            if not word in word_to_index:\n",
    "                word_to_index[word] = word_index\n",
    "                word_index += 1\n",
    "    index_to_word = {v:k for k,v in word_to_index.items()}\n",
    "    print(f'사전 크기: {len(word_to_index)}, {len(index_to_word)}')\n",
    "\n",
    "    # 벡터화\n",
    "    question_vector = []\n",
    "    answer_vector = []\n",
    "    for question in question_corpus:\n",
    "        vector = [word_to_index[word] for word in question]\n",
    "        question_vector.append(vector)\n",
    "    for answer in answer_corpus:\n",
    "        vector = [word_to_index[word] for word in answer]\n",
    "        answer_vector.append(vector)\n",
    "\n",
    "    # 패딩 처리\n",
    "    enc_train = tf.keras.preprocessing.sequence.pad_sequences(question_vector, padding='post')\n",
    "    dec_train = tf.keras.preprocessing.sequence.pad_sequences(answer_vector, padding='post')\n",
    "\n",
    "    return enc_train, dec_train, word_to_index, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "860ca9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 11662, 대답: 11662\n",
      "전체: 23324\n",
      "사전 크기: 7145, 7145\n"
     ]
    }
   ],
   "source": [
    "# 말뭉치에 대해 벡터화 수행\n",
    "enc_train, dec_train, word_to_index, index_to_word = vectorize(que_corpus, ans_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03248208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11662, 31) (11662, 42)\n"
     ]
    }
   ],
   "source": [
    "print(enc_train.shape, dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa8cd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bfc42e",
   "metadata": {},
   "source": [
    "### 6. 훈련하기\n",
    "- Transformer 모델은 Node 17의 모델 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54d41b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5544c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 마스크 생성\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71b2d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 룩어헤드 마스크 생성\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fe2166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마스크 생성 함수\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e489aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티헤드어텐션\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_qk += (mask * -1e9)\n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "\n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "\n",
    "        out, attention_weights = self.scaled_dot_product_attention(WQ_splits, WK_splits, WV_splits, mask)\n",
    "\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3480e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position-wise Feed Forward Network\n",
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0de096fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 레이어\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9431ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 레이어\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1a5f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "\n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "\n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "536f261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "\n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e35b9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, src_vocab_size, tgt_vocab_size, pos_len, dropout=0.2, shared_fc=True, shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc:\n",
    "            out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "\n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3aca898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "transformer = Transformer(n_layers=2, d_model=512, n_heads=8, d_ff=2048, src_vocab_size=VOCAB_SIZE, tgt_vocab_size=VOCAB_SIZE, pos_len=200, dropout=0.3, shared_fc=True, shared_emb=True)\n",
    "\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d918b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba45a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저\n",
    "learning_rate = LearningRateScheduler(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34ec710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "712ed453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7c22670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab18789092f48989f876d13be5c8471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa9d9b1c0c847c69e9c0d4831145a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1862a650a6f74be4a399bdd9947ce252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = train_step(enc_train[idx:idx+BATCH_SIZE], dec_train[idx:idx+BATCH_SIZE], transformer, optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0838da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화 함수\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, square=True, vmin=0.0, vmax=1.0, cbar=False, ax=ax, xticklabels=x, yticklabels=y)\n",
    "\n",
    "    #print(enc_attns.shape, dec_attns.shape, dec_enc_attns.shape)\n",
    "    for layer in range(1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(16, 6))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(1):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(16, 6))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(1):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(16, 6))\n",
    "        for h in range(1):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba5bcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index를 스트링으로 변환\n",
    "def index_to_string(vector, index_to_word):\n",
    "    res = \"\"\n",
    "    for index in vector:\n",
    "        if index in index_to_word:\n",
    "            res += index_to_word[index] + \" \"\n",
    "        else:\n",
    "            res += \"<ERROR> \"\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91a705e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대답 생성 함수\n",
    "def evaluate(sentence, model, tokenizer, word_to_index, index_to_word):\n",
    "    # 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 토큰화\n",
    "    tokens = tokenizer.morphs(sentence)\n",
    "    \n",
    "    # 벡터화\n",
    "    vectors = [word_to_index[word] if word in word_to_index else UNKNOWN_INDEX for word in tokens]\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([vectors], maxlen=enc_train.shape[-1], padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([START_INDEX], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(_input, output, enc_padding_mask, combined_mask, dec_padding_mask)\n",
    "\n",
    "        predicted_id = tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if END_INDEX == predicted_id:\n",
    "            #result = tgt_tokenizer.decode_ids(ids)\n",
    "            result = index_to_string(ids, index_to_word)\n",
    "            return vectors, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = index_to_string(ids, index_to_word)\n",
    "\n",
    "    return vectors, result, enc_attns, dec_attns, dec_enc_attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1acbcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문하고 대답을 얻어오는 함수\n",
    "def query(sentence):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = evaluate(sentence, transformer, mecab, word_to_index, index_to_word)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    #if plot_attention:\n",
    "    #    visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6fb1e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오늘 날씨 어때?\n",
      "Predicted translation: 저 도 좋 은 생각 해 보 세요 . \n"
     ]
    }
   ],
   "source": [
    "query(\"오늘 날씨 어때?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
