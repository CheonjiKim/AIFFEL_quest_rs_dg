{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fadbccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e5c95",
   "metadata": {},
   "source": [
    "## 1. Tokenizer 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0aa489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/bert_pretrain/data/kowiki.txt --model_prefix=ko_namuwiki_8000 --vocab_size=8007 --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS] --user_defined_symbols=[SEP],[CLS],[MASK]\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/bert_pretrain/data/kowiki.txt\n",
      "  input_format: \n",
      "  model_prefix: ko_namuwiki_8000\n",
      "  model_type: BPE\n",
      "  vocab_size: 8007\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [SEP]\n",
      "  user_defined_symbols: [CLS]\n",
      "  user_defined_symbols: [MASK]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: [UNK]\n",
      "  bos_piece: [BOS]\n",
      "  eos_piece: [EOS]\n",
      "  pad_piece: [PAD]\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/bert_pretrain/data/kowiki.txt\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 2000000 lines\n",
      "trainer_interface.cc(117) LOG(WARNING) Too many sentences are loaded! (2451287), which may slow down training.\n",
      "trainer_interface.cc(119) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(122) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2451287 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [UNK]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [BOS]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [EOS]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [SEP]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [CLS]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [MASK]\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=287452241\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=4411\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2450254 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2450254\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 7050692\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1781571 min_freq=424\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=576838 size=20 all=581927 active=38577 piece=▁아\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=390836 size=40 all=591445 active=48095 piece=▁유\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=297873 size=60 all=601378 active=58028 piece=에는\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=244712 size=80 all=609974 active=66624 piece=▁성\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=194372 size=100 all=616449 active=73099 piece=까지\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=193674 min_freq=462\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=176838 size=120 all=625299 active=38770 piece=▁우\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=154294 size=140 all=632274 active=45745 piece=▁파\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=140625 size=160 all=639734 active=53205 piece=00\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=125983 size=180 all=645481 active=58952 piece=▁요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=114855 size=200 all=649839 active=63310 piece=리아\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=114086 min_freq=457\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=106760 size=220 all=657338 active=39316 piece=▁같은\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=100770 size=240 all=662564 active=44542 piece=▁왕\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=96037 size=260 all=670536 active=52514 piece=▁목\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=88392 size=280 all=675441 active=57419 piece=▁f\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=81678 size=300 all=681701 active=63679 piece=▁선수\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=80870 min_freq=446\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=77144 size=320 all=686930 active=39163 piece=▁때문에\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=73218 size=340 all=691000 active=43233 piece=▁조선\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=68829 size=360 all=695717 active=47950 piece=▁천\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=64009 size=380 all=700839 active=53072 piece=▁196\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=60953 size=400 all=706675 active=58908 piece=▁돌\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=60762 min_freq=435\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=58542 size=420 all=711350 active=39712 piece=▁다시\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=55779 size=440 all=715377 active=43739 piece=▁K\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=52528 size=460 all=721839 active=50201 piece=▁모두\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=49784 size=480 all=727356 active=55718 piece=▁히\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47637 size=500 all=733038 active=61400 piece=▁전쟁\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=47558 min_freq=423\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=45919 size=520 all=738287 active=41703 piece=▁있어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=44025 size=540 all=743886 active=47302 piece=▁중심\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42378 size=560 all=748357 active=51773 piece=▁N\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40922 size=580 all=752114 active=55530 piece=▁H\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39922 size=600 all=755142 active=58558 piece=le\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=39768 min_freq=414\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38924 size=620 all=761204 active=43650 piece=▁검\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37771 size=640 all=767376 active=49822 piece=란드\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36292 size=660 all=772837 active=55283 piece=정을\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=35134 size=680 all=778715 active=61161 piece=▁설립\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34016 size=700 all=783719 active=66165 piece=▁역사\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=34003 min_freq=400\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33144 size=720 all=787243 active=42507 piece=▁만들어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32383 size=740 all=791538 active=46802 piece=▁시간\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31645 size=760 all=795131 active=50395 piece=▁측\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30941 size=780 all=798845 active=54109 piece=과의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30041 size=800 all=803050 active=58314 piece=도는\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=30023 min_freq=392\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29448 size=820 all=808546 active=45099 piece=▁난\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28836 size=840 all=813895 active=50448 piece=▁21\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28270 size=860 all=818654 active=55207 piece=▁찾\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27299 size=880 all=824625 active=61177 piece=되지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26862 size=900 all=828285 active=64837 piece=하자\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=26833 min_freq=381\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26060 size=920 all=832595 active=45199 piece=부에\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25504 size=940 all=838824 active=51428 piece=수의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24726 size=960 all=843322 active=55926 piece=▁남아\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24083 size=980 all=848416 active=61020 piece=▁않는다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23647 size=1000 all=853601 active=66205 piece=인민\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=23602 min_freq=368\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23176 size=1020 all=859529 active=48367 piece=▁마지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22849 size=1040 all=863129 active=51967 piece=▁시리즈\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22293 size=1060 all=868678 active=57516 piece=제로\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21851 size=1080 all=873075 active=61913 piece=시의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21377 size=1100 all=878277 active=67115 piece=해야\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=21369 min_freq=355\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21043 size=1120 all=882003 active=47093 piece=▁녹\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20625 size=1140 all=886266 active=51356 piece=▁인구는\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20185 size=1160 all=889382 active=54472 piece=ac\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19762 size=1180 all=894738 active=59828 piece=인은\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19447 size=1200 all=899565 active=64655 piece=50\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=19432 min_freq=347\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19118 size=1220 all=903215 active=48471 piece=광역\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18777 size=1240 all=908007 active=53263 piece=수는\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18396 size=1260 all=913268 active=58524 piece=인민공\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18040 size=1280 all=917389 active=62645 piece=▁긴\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17659 size=1300 all=922177 active=67433 piece=▁전통\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=17629 min_freq=335\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17404 size=1320 all=926354 active=50086 piece=▁망\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17093 size=1340 all=929494 active=53226 piece=단의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16931 size=1360 all=934269 active=58001 piece=▁인간\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16719 size=1380 all=939872 active=63604 piece=▁바로\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16586 size=1400 all=943447 active=67179 piece=▁탑\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16584 min_freq=327\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16331 size=1420 all=947545 active=51069 piece=▁태양\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16086 size=1440 all=952041 active=55565 piece=▁경기에서\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15873 size=1460 all=957568 active=61092 piece=▁동일\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15577 size=1480 all=962681 active=66205 piece=드를\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15352 size=1500 all=966310 active=69834 piece=▁뮤\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=15328 min_freq=318\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15103 size=1520 all=968851 active=50741 piece=id\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14971 size=1540 all=972545 active=54435 piece=▁옥\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14723 size=1560 all=977306 active=59196 piece=비전\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14495 size=1580 all=982182 active=64072 piece=▁대부분의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14292 size=1600 all=985970 active=67860 piece=▁갑\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=14280 min_freq=311\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14118 size=1620 all=990010 active=53173 piece=회는\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13982 size=1640 all=993514 active=56677 piece=▁사고\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13729 size=1660 all=997224 active=60387 piece=cm\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13567 size=1680 all=1001600 active=64762 piece=▁뛰어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13433 size=1700 all=1006574 active=69736 piece=▁더욱\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13420 min_freq=303\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13135 size=1720 all=1011076 active=54820 piece=지역\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12940 size=1740 all=1015431 active=59175 piece=▁선언\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12821 size=1760 all=1020339 active=64083 piece=▁어려\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12640 size=1780 all=1023221 active=66965 piece=▁칭\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12505 size=1800 all=1028177 active=71921 piece=▁옛\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12503 min_freq=295\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12409 size=1820 all=1033793 active=56931 piece=ce\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12253 size=1840 all=1037183 active=60321 piece=▁그들의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12091 size=1860 all=1041900 active=65038 piece=▁단체\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11934 size=1880 all=1045379 active=68517 piece=▁예술\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11799 size=1900 all=1048007 active=71145 piece=라의\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11799 min_freq=288\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11693 size=1920 all=1050313 active=54358 piece=▁불구하고\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11594 size=1940 all=1053703 active=57748 piece=▁분리\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11496 size=1960 all=1057998 active=62043 piece=▁사이의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11381 size=1980 all=1063418 active=67463 piece=단이\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11289 size=2000 all=1067885 active=71930 piece=im\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11277 min_freq=281\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11133 size=2020 all=1071888 active=57167 piece=▁등과\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10994 size=2040 all=1077153 active=62432 piece=법을\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10895 size=2060 all=1081334 active=66613 piece=▁괴\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10776 size=2080 all=1084885 active=70164 piece=러스\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10692 size=2100 all=1089330 active=74609 piece=▁깨\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10688 min_freq=274\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10597 size=2120 all=1091576 active=56585 piece=릭터\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10496 size=2140 all=1095180 active=60189 piece=▁확장\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10396 size=2160 all=1100510 active=65519 piece=었던\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10271 size=2180 all=1104334 active=69343 piece=▁남부\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10143 size=2200 all=1108628 active=73637 piece=▁스포츠\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10136 min_freq=268\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10057 size=2220 all=1111848 active=58430 piece=▁이외\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9957 size=2240 all=1115235 active=61817 piece=▁서식\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9848 size=2260 all=1120216 active=66798 piece=▁작용\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9732 size=2280 all=1124443 active=71025 piece=▁이야기\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9655 size=2300 all=1129106 active=75688 piece=▁성립\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9653 min_freq=261\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9570 size=2320 all=1132064 active=59284 piece=▁떨어진\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9473 size=2340 all=1135883 active=63103 piece=시를\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9352 size=2360 all=1139681 active=66901 piece=▁히로\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9289 size=2380 all=1142636 active=69856 piece=▁부정\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9219 size=2400 all=1147544 active=74764 piece=▁2020\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9217 min_freq=256\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9137 size=2420 all=1150230 active=60032 piece=▁상징\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9028 size=2440 all=1153890 active=63692 piece=▁1950\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8965 size=2460 all=1157151 active=66953 piece=▁표시\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8889 size=2480 all=1162268 active=72070 piece=▁사용된다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8828 size=2500 all=1165804 active=75606 piece=▁아일랜드\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8826 min_freq=251\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8738 size=2520 all=1169223 active=61615 piece=▁동생\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8694 size=2540 all=1173546 active=65938 piece=ie\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8641 size=2560 all=1176802 active=69194 piece=▁경상북도\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8570 size=2580 all=1180886 active=73278 piece=▁계승\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8489 size=2600 all=1184747 active=77139 piece=▁1985\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8487 min_freq=246\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8434 size=2620 all=1188193 active=62666 piece=력의\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8345 size=2640 all=1191415 active=65888 piece=인지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8270 size=2660 all=1196857 active=71330 piece=▁달성\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8223 size=2680 all=1200791 active=75264 piece=▁충돌\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8139 size=2700 all=1202837 active=77310 piece=ak\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8133 min_freq=241\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8061 size=2720 all=1205959 active=63019 piece=▁2,\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8008 size=2740 all=1208089 active=65149 piece=)\"\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7956 size=2760 all=1210710 active=67770 piece=▁둘러\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7894 size=2780 all=1213790 active=70850 piece=워드\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7817 size=2800 all=1216934 active=73994 piec"
     ]
    }
   ],
   "source": [
    "# 데이터 읽어와서 SentencePiece로 Vocab 모델 만들기\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "\n",
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "#prefix = os.getenv('HOME')+'/aiffel/bert_pretrain/models/ko_32000'\n",
    "prefix = \"ko_namuwiki_8000\"\n",
    "vocab_size = 8000\n",
    "spm.SentencePieceTrainer.train(f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={vocab_size + 7} --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS] --user_defined_symbols=[SEP],[CLS],[MASK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7c54f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 모델 로딩\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f'{prefix}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60e7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 리스트 만들기 함수\n",
    "def make_vocab_list(vocab):\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "            if not vocab.is_unknown(id):\n",
    "                vocab_list.append(vocab.IdToPiece(id))\n",
    "\n",
    "    print(f'Vocab 크기: {len(vocab_list)}')\n",
    "\n",
    "    return vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48bca9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab 크기: 8000\n"
     ]
    }
   ],
   "source": [
    "# 단어 리스트 만들기\n",
    "vocab_list = make_vocab_list(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096f3de",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 (1) MASK 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bdd484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
    "    :param vocab_list: vocab list (random token 용)\n",
    "    :return tokens: mask된 tokens\n",
    "    :return mask_idx: mask된 token의 index\n",
    "    :return mask_label: mask된 token의 원래 값\n",
    "    \"\"\"\n",
    "    # 단어 단위로 mask 하기 위해서 index 분할 (띄어쓰기)\n",
    "    cand_idx = []  # word 단위의 index array\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):  # u\"\\u2581\"는 단어의 시작을 의미하는 값\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "\n",
    "    # random mask를 위해서 순서를 섞음 (shuffle)\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    mask_lms = []  # mask 된 값\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "            continue\n",
    "        dice = random.random()  # 0과 1 사이의 확률 값\n",
    "\n",
    "        for index in index_set:\n",
    "            masked_token = None\n",
    "            if dice < 0.8:  # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: # 10% keep original\n",
    "                masked_token = tokens[index]\n",
    "            else:  # 10% random word\n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "\n",
    "    # mask_lms 정렬 후 mask_idx, mask_label 추출 (sorted 사용)\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80bd3c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n",
      "tokens_org\n",
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '▁추', '적', '추', '적', '[MASK]', '[MASK]', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁아시', '위가', '듄', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '부로', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', 'O', '▁우', 'oc', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁말했다', '▁전', '부터', '▁콜', '록', '거', '리는', '[MASK]', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
      "\n",
      "mask_idx   : [5, 6, 18, 19, 20, 28, 38, 39, 40, 45, 46, 47, 78, 85]\n",
      "mask_label : ['▁비', '가', '▁손', '님', '이', '▁전', '▁받아', '보', '는', '▁백', '통', '화', '▁포', '▁아내']\n"
     ]
    }
   ],
   "source": [
    "# 마스크 생성 결과 확인\n",
    "import copy\n",
    "import random\n",
    "\n",
    "string_a = \"추적추적 비가 내리는 날이었어 그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
    "string_b = \"손바닥 위엔 기쁨의 눈물이 흘러 컬컬한 목에 모주 한잔을 적셔 몇 달 포 전부터 콜록거리는 아내 생각에 그토록 먹고 싶다던\"\n",
    "tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
    "print(tokens_org)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
    "\n",
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens, \"\\n\")\n",
    "\n",
    "print(\"mask_idx   :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb186c7",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리 (2) NSP pair 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2a18957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이\n",
    "n_test_seq = 64\n",
    "# 최소 길이\n",
    "min_seq = 8\n",
    "# [CLS], tokens_a, [SEB], tokens_b, [SEP]\n",
    "max_seq = n_test_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c934d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96d16efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    # for CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        # [[YOUR CODE]]\n",
    "        current_chunk.append(doc[i])  # line 단위로 추가\n",
    "        current_length += len(doc[i])  # current_chunk의 token 수\n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "            #print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "            # token a\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            # token b\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            if random.random() < 0.5:  # 50% 확률로 swap\n",
    "                is_next = 0    # False\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1   # True\n",
    "            # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "\n",
    "            #print(\"is_next:\", is_next)\n",
    "            #print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "            #print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "            #######################################\n",
    "\n",
    "            # tokens & segment 생성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "            #print(\"tokens:\", len(tokens), tokens)\n",
    "            #print(\"segment:\", len(segment), segment)\n",
    "\n",
    "            # mask\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "            #print(\"masked tokens:\", len(tokens), tokens)\n",
    "            #print(\"masked index:\", len(mask_idx), mask_idx)\n",
    "            #print(\"masked label:\", len(mask_label), mask_label)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "            #######################################\n",
    "            #print()\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8b21a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        #print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    # 특수문자 7개를 제외한 vocab_list 생성\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):        # 생성되는 단어 목록이 unknown인 경우는 제거합니다.\n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "    print(f'vocab size: {len(vocab_list)}')\n",
    "    # line count 확인\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "    print(f'전체 줄 수: {line_cnt}')\n",
    "\n",
    "    count = line_cnt\n",
    "\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)\n",
    "                    if 0 < len(doc):\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        doc = []\n",
    "                        if 0 < count:  # 테스트를 위해서 부분 처리함\n",
    "                            count -= 1\n",
    "                        else:\n",
    "                            break\n",
    "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "                save_pretrain_instances(out_f, doc)\n",
    "                doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "21494dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 8000\n",
      "전체 줄 수: 3957761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80338e1f50cf4aacb90383d57ebcdcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NSP 처리\n",
    "pretrain_json_path = \"bert_pre_train.json\"\n",
    "\n",
    "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e52ba",
   "metadata": {},
   "source": [
    "## 4. 데이터 전처리 (3) 데이터셋 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7dcebd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "918189"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 확인\n",
    "total = 0\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dc47589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "66bc639c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0eeaa301c640a2b868212e4398a468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38/2205850736.py:42: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_38/2205850736.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_38/2205850736.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load early stop 100000 100000\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터셋 생성 - 단어수는 100000개로 설정\n",
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4160c3",
   "metadata": {},
   "source": [
    "## 5. BERT 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8dcb3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d59f0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f71740a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6bce3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d5968f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96439d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d113d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8295f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: position embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0cc4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c63fe539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d2c77928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d7c770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81ac2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f208369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6571960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ddf80a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 8007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22691c9",
   "metadata": {},
   "source": [
    "## 6. pretrain 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63996bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss 함수\n",
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "220d7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy 함수\n",
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # 정확도 계산\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d967c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate 스케줄링 함수\n",
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2a3ffebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate 스케줄러를 시각화\n",
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1f9eb9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b9f41d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 4485632     enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 8007)   0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 4,551,936\n",
      "Trainable params: 4,551,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cbbd7bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 15630\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일 설정\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d265485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 204s 128ms/step - loss: 19.8267 - nsp_loss: 0.6559 - mlm_loss: 19.1708 - nsp_acc: 0.5840 - mlm_lm_acc: 0.1072\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.10717, saving model to bert_pre_train.hdf5\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 202s 129ms/step - loss: 17.7675 - nsp_loss: 0.6304 - mlm_loss: 17.1370 - nsp_acc: 0.6104 - mlm_lm_acc: 0.1292\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.10717 to 0.12919, saving model to bert_pre_train.hdf5\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 202s 130ms/step - loss: 16.9962 - nsp_loss: 0.6187 - mlm_loss: 16.3775 - nsp_acc: 0.6256 - mlm_lm_acc: 0.1373\n",
      "\n",
      "Epoch 00003: mlm_lm_acc improved from 0.12919 to 0.13735, saving model to bert_pre_train.hdf5\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 202s 129ms/step - loss: 15.7864 - nsp_loss: 0.6143 - mlm_loss: 15.1721 - nsp_acc: 0.6353 - mlm_lm_acc: 0.1564\n",
      "\n",
      "Epoch 00004: mlm_lm_acc improved from 0.13735 to 0.15643, saving model to bert_pre_train.hdf5\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 202s 129ms/step - loss: 14.4079 - nsp_loss: 0.6094 - mlm_loss: 13.7986 - nsp_acc: 0.6475 - mlm_lm_acc: 0.1829\n",
      "\n",
      "Epoch 00005: mlm_lm_acc improved from 0.15643 to 0.18286, saving model to bert_pre_train.hdf5\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 202s 129ms/step - loss: 13.8295 - nsp_loss: 0.6017 - mlm_loss: 13.2278 - nsp_acc: 0.6573 - mlm_lm_acc: 0.1974\n",
      "\n",
      "Epoch 00006: mlm_lm_acc improved from 0.18286 to 0.19743, saving model to bert_pre_train.hdf5\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 202s 129ms/step - loss: 13.4720 - nsp_loss: 0.5932 - mlm_loss: 12.8788 - nsp_acc: 0.6744 - mlm_lm_acc: 0.2069\n",
      "\n",
      "Epoch 00007: mlm_lm_acc improved from 0.19743 to 0.20693, saving model to bert_pre_train.hdf5\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 202s 129ms/step - loss: 13.2423 - nsp_loss: 0.5842 - mlm_loss: 12.6582 - nsp_acc: 0.6887 - mlm_lm_acc: 0.2132\n",
      "\n",
      "Epoch 00008: mlm_lm_acc improved from 0.20693 to 0.21324, saving model to bert_pre_train.hdf5\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 202s 130ms/step - loss: 13.1079 - nsp_loss: 0.5766 - mlm_loss: 12.5313 - nsp_acc: 0.7005 - mlm_lm_acc: 0.2168\n",
      "\n",
      "Epoch 00009: mlm_lm_acc improved from 0.21324 to 0.21678, saving model to bert_pre_train.hdf5\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 202s 129ms/step - loss: 13.0466 - nsp_loss: 0.5724 - mlm_loss: 12.4742 - nsp_acc: 0.7072 - mlm_lm_acc: 0.2181\n",
      "\n",
      "Epoch 00010: mlm_lm_acc improved from 0.21678 to 0.21806, saving model to bert_pre_train.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "\n",
    "# 학습\n",
    "history = pre_train_model.fit(pre_train_inputs, pre_train_labels, epochs=epochs, batch_size=batch_size, callbacks=[save_weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de2014",
   "metadata": {},
   "source": [
    "## 7. 프로젝트 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "15231ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 학습 결과 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
    "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
    "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eff1f9",
   "metadata": {},
   "source": [
    "## 회고\n",
    "- 사전 학습된 모델을 만드는 것이라서, Loss가 감소하고, Acc가 증가하는 것만 확인해 봄\n",
    "- 빠른 학습을 위해 90만 개 이상되는 데이터 중 10만 개만 이용하였으며, 10 epoch에 35분 정도의 시간이 걸림\n",
    "- MLM 과정과 NSP 과정의 구현이 다소 어려웠음.\n",
    "- 전체적인 동작의 이해를 위해 자세한 분석을 하는 것이 좋을 것 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7744eedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
